# Cursor Rules for Databricks App Template

This is a Databricks App template with FastAPI backend and React TypeScript frontend. The repository includes comprehensive automation scripts and follows a specific development workflow.

## Repository Structure

### Core Directories
- `server/` - FastAPI backend with routers and services
- `client/` - React TypeScript frontend with Vite
- `setup_utils/` - Modular setup system with dependency checkers
- `scripts/` - Development automation scripts
- `claude_scripts/` - Claude-specific testing and debugging scripts
- `docs/` - Documentation including Databricks APIs and design docs

### Key Files
- `app.yaml` - Databricks Apps configuration (DO NOT MODIFY)
- `pyproject.toml` - Python dependencies with uv
- `client/package.json` - Frontend dependencies with bun
- `.env.local` - Environment configuration (auto-generated by setup.sh)

## Development Scripts

### Setup & Configuration
- `./setup.sh` - Interactive environment setup, installs dependencies, configures Databricks auth
- `./setup.sh --auto-close` - Setup with auto-close terminal on completion

### Development Workflow
- `./watch.sh` - Start development servers (frontend + backend) with hot reload
- `./watch.sh --prod` - Production mode (backend only, frontend served by FastAPI)
- `./fix.sh` - Format Python (ruff) and TypeScript (prettier) code

### Deployment & Monitoring
- `./deploy.sh` - Deploy to Databricks Apps platform
- `./deploy.sh --create` - Create app if it doesn't exist
- `./deploy.sh --verbose` - Detailed deployment logs
- `./app_status.sh` - Check deployed app status
- `./app_status.sh --verbose` - Detailed status with JSON and workspace files
- `./run_app_local.sh` - Run app locally for debugging deployment issues
- `./run_app_local.sh --verbose` - Detailed local debugging

### Utility Scripts
- `scripts/make_fastapi_client.py` - Generate TypeScript client from OpenAPI spec
- `scripts/generate_semver_requirements.py` - Create requirements.txt from pyproject.toml

## Environment Configuration

The setup script creates `.env.local` with:
- `DATABRICKS_AUTH_TYPE` - "pat" or "databricks-cli"
- `DATABRICKS_HOST` - Workspace URL (for PAT auth)
- `DATABRICKS_TOKEN` - Personal Access Token (for PAT auth)
- `DATABRICKS_CONFIG_PROFILE` - CLI profile name (for profile auth)
- `DATABRICKS_APP_NAME` - App name for deployment
- `DBA_SOURCE_CODE_PATH` - Workspace path for source code

## Development Workflow

### First Time Setup
1. Run `./setup.sh` to configure environment and install dependencies
2. The script will guide you through Databricks authentication setup
3. All required tools (uv, bun, Node.js, Databricks CLI) are automatically checked/installed

### Daily Development
1. Run `./watch.sh` to start development servers
2. Frontend: http://localhost:5173
3. Backend: http://localhost:8000
4. API Docs: http://localhost:8000/docs
5. Use `./fix.sh` to format code before committing

### Deployment
1. Run `./deploy.sh` to deploy to Databricks Apps
2. Use `./app_status.sh` to monitor deployment
3. Visit app URL + `/logz` for deployment logs (browser auth required)

## Claude Commands

Claude understands these natural language commands:
- "start the devserver" → Runs `./watch.sh`
- "kill the devserver" → Stops background processes
- "fix the code" → Runs `./fix.sh`
- "deploy the app" → Runs `./deploy.sh`
- "add a new API endpoint" → Creates FastAPI routes
- "create a new React component" → Builds UI components
- "debug this error" → Analyzes logs and fixes issues

## Tech Stack

### Backend
- FastAPI with automatic OpenAPI generation
- uv for Python package management
- Databricks SDK for workspace integration
- MLflow[databricks] for AI/ML capabilities

### Frontend
- React 18 with TypeScript
- Vite for fast development
- shadcn/ui components with Tailwind CSS
- Auto-generated TypeScript client from FastAPI

### Development Tools
- Hot reloading for both frontend and backend
- Automatic TypeScript client generation
- Code formatting with ruff (Python) and prettier (TypeScript)
- Background process management with comprehensive logging

## Troubleshooting

### Common Issues
- Port conflicts: Kill processes on 8000/5173 or modify ports in scripts
- Missing tools: Re-run `./setup.sh` to install missing dependencies
- Auth issues: Run `databricks auth login` or set `DATABRICKS_TOKEN` env var
- Build errors: Check `client/package.json` and `pyproject.toml` for version conflicts

### Debug Commands
- `tail -f /tmp/databricks-app-watch.log` - View development logs
- `ps aux | grep databricks-app` - Check running processes
- `./run_app_local.sh` - Test app locally before deployment
- `./app_status.sh --verbose` - Detailed deployment status

## Important Notes

- DO NOT modify `app.yaml` - it's the Databricks Apps configuration
- The `/dba` command provides a complete guided workflow from setup to deployment
- All scripts include comprehensive error handling and user guidance
- Environment variables are managed through `.env.local` (excluded from version control)
- The repository includes extensive documentation in `docs/` and `CLAUDE.md`

## File Locations

- Development logs: `/tmp/databricks-app-watch.log`
- Process PID: `/tmp/databricks-app-watch.pid`
- Environment config: `.env.local`
- API client: `client/src/fastapi_client/`
- UI components: `client/src/components/`
- API routes: `server/routers/`
- Business logic: `server/services/`
